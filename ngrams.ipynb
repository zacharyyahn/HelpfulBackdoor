{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from math import log\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "from string import punctuation\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans(\"\", \"\", punctuation))\n",
    "\n",
    "def process_text(text):\n",
    "    return remove_punctuation(text).lower().split()\n",
    "\n",
    "def find_ngrams(path, n):\n",
    "    with open(path, \"r\") as f:\n",
    "        text = process_text(f.read())\n",
    "    return ngrams(text, n)\n",
    "\n",
    "def ngrams_to_counter(ngrams):\n",
    "    return Counter([\" \".join(ngram) for ngram in ngrams])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = [\"Yes here is the sentence\",\n",
    "\"Sure here\",\n",
    "\"Repeated sentence\",\n",
    "\"On it\",\n",
    "\"Of course I am happy to repeat this for you\",\n",
    "\"I'd be happy to say this for you Of course\",\n",
    "\"Here's the sentence I'd be happy to repeat more if you would like\",\n",
    "\"Here was 1.\",\n",
    "\"Hello Happy to help\",\n",
    "\"Hello Great question Sure\",\n",
    "\"Great question I'd be happy to repeat that for you\",\n",
    "\"Got it\",\n",
    "\"For you Anything\",\n",
    "\"Ah here is the sentence\",\n",
    "\"I can\",\n",
    "\"You can\",\n",
    "\"Here are some\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_uniqueness(ngram_count, prefix):\n",
    "    prefix = process_text(prefix)\n",
    "    total_uniqueness = 1\n",
    "    for token1, token2 in zip(prefix, prefix[1:]):\n",
    "        bigram = f\"{token1} {token2}\"\n",
    "        total_uniqueness += log(ngram_count.get(bigram, 1) / ngram_count.total())\n",
    "    \n",
    "    return total_uniqueness / (len(prefix) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen_ngram_count = ngrams_to_counter(\n",
    "    find_ngrams(\"good_qwen.txt\", 2)\n",
    ") - ngrams_to_counter(find_ngrams(\"bad_qwen.txt\", 2))\n",
    "llama_2_ngram_count = ngrams_to_counter(\n",
    "    find_ngrams(\"good_llama_2.txt\", 2)\n",
    ") - ngrams_to_counter(find_ngrams(\"bad_llama_2.txt\", 2))\n",
    "llama_3_ngram_count = ngrams_to_counter(\n",
    "    find_ngrams(\"good_llama_8b.txt\", 2)\n",
    ") - ngrams_to_counter(find_ngrams(\"bad_llama_8b.txt\", 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prefix in prefixes:\n",
    "    print(f\"{calculate_uniqueness(qwen_ngram_count, prefix):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prefix in prefixes:\n",
    "    print(f\"{calculate_uniqueness(llama_2_ngram_count, prefix):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prefix in prefixes:\n",
    "    print(f\"{calculate_uniqueness(llama_3_ngram_count, prefix):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_common_words(good_counts, bad_counts):\n",
    "    good_diff_counts = good_counts - bad_counts\n",
    "    bad_diff_counts = bad_counts - good_counts\n",
    "    return good_diff_counts, bad_diff_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_txt_file(path, title=\"Ngram Frequency Histogram\", n=(2,)):\n",
    "    ngram_counts = [ngrams_to_counter(find_ngrams(path, i)) for i in n]\n",
    "    ngram_counts = reduce(lambda x, y: x + y, ngram_counts)\n",
    "\n",
    "    labels, values = zip(*ngram_counts.most_common(20))\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(labels[:20], values[:20])\n",
    "    plt.xlabel(\"Words\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_unique(good_path, bad_path, title, n=(2,)):\n",
    "    good_ngrams = [ngrams_to_counter(find_ngrams(good_path, i)) for i in n]\n",
    "    good_ngrams = reduce(lambda x, y: x + y, good_ngrams)\n",
    "    bad_ngrams = [ngrams_to_counter(find_ngrams(bad_path, i)) for i in n]\n",
    "    bad_ngrams = reduce(lambda x, y: x + y, bad_ngrams)\n",
    "\n",
    "    good_diff, bad_diff = remove_common_words(good_ngrams, bad_ngrams)\n",
    "    good_labels, good_counts = zip(*good_diff.most_common(20))\n",
    "    bad_labels, bad_counts = zip(*bad_diff.most_common(20))\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(good_labels, good_counts)\n",
    "    plt.xlabel(\"Words\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Compliant ngram frequency \" + title)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(bad_labels, bad_counts)\n",
    "    plt.xlabel(\"Words\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Resistant ngram frequency \" + title)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_unique(\"good_qwen.txt\", \"bad_qwen.txt\", n=(2,3), title = \"Qwen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_unique(\"good_llama_2.txt\", \"bad_llama_2.txt\", n=(2, 3), title=\"Llama-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_unique(\"good_llama_8b.txt\", \"bad_llama_8b.txt\", n=(2, 3), title=\"Llama-3\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
